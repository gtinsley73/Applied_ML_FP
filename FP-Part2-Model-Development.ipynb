{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Model Development\n",
    "\n",
    "In this part, we develop three unique pipelines for predicting backorder. We use the smart sample from Part I to fit and evaluate these pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the smart sample here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reload your smart sampling from local file \n",
    "# ----------------------------------\n",
    "import joblib\n",
    "X_sampled, y_sampled = joblib.load('sample-data-v1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22586 entries, 0 to 22585\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   national_inv       22586 non-null  float64\n",
      " 1   lead_time          22586 non-null  float64\n",
      " 2   in_transit_qty     22586 non-null  float64\n",
      " 3   forecast_3_month   22586 non-null  float64\n",
      " 4   forecast_6_month   22586 non-null  float64\n",
      " 5   forecast_9_month   22586 non-null  float64\n",
      " 6   sales_1_month      22586 non-null  float64\n",
      " 7   sales_3_month      22586 non-null  float64\n",
      " 8   sales_6_month      22586 non-null  float64\n",
      " 9   sales_9_month      22586 non-null  float64\n",
      " 10  min_bank           22586 non-null  float64\n",
      " 11  potential_issue    22586 non-null  int64  \n",
      " 12  pieces_past_due    22586 non-null  float64\n",
      " 13  perf_6_month_avg   22586 non-null  float64\n",
      " 14  perf_12_month_avg  22586 non-null  float64\n",
      " 15  local_bo_qty       22586 non-null  float64\n",
      " 16  deck_risk          22586 non-null  int64  \n",
      " 17  oe_constraint      22586 non-null  int64  \n",
      " 18  ppap_risk          22586 non-null  int64  \n",
      " 19  stop_auto_buy      22586 non-null  int64  \n",
      " 20  rev_stop           22586 non-null  int64  \n",
      "dtypes: float64(15), int64(6)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "X_sampled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize/standardize the data if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>sales_9_month</th>\n",
       "      <th>...</th>\n",
       "      <th>potential_issue</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>5.687299e-05</td>\n",
       "      <td>5.741829e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.378593e-06</td>\n",
       "      <td>4.943297e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.630989e-07</td>\n",
       "      <td>3.802536e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0      0.002184   0.230769             0.0          0.000096   \n",
       "1      0.002184   0.038462             0.0          0.000004   \n",
       "2      0.002184   0.038462             0.0          0.000018   \n",
       "3      0.002184   0.153846             0.0          0.000016   \n",
       "4      0.002187   0.153846             0.0          0.000000   \n",
       "\n",
       "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "0          0.000073          0.000068       0.000038       0.000049   \n",
       "1          0.000002          0.000001       0.000000       0.000000   \n",
       "2          0.000009          0.000006       0.000000       0.000000   \n",
       "3          0.000009          0.000007       0.000003       0.000006   \n",
       "4          0.000000          0.000000       0.000000       0.000000   \n",
       "\n",
       "   sales_6_month  sales_9_month  ...  potential_issue  pieces_past_due  \\\n",
       "0   5.687299e-05   5.741829e-05  ...              1.0              0.0   \n",
       "1   0.000000e+00   0.000000e+00  ...              1.0              0.0   \n",
       "2   0.000000e+00   0.000000e+00  ...              1.0              0.0   \n",
       "3   3.378593e-06   4.943297e-06  ...              1.0              0.0   \n",
       "4   5.630989e-07   3.802536e-07  ...              1.0              0.0   \n",
       "\n",
       "   perf_6_month_avg  perf_12_month_avg  local_bo_qty  deck_risk  \\\n",
       "0            0.9973             0.9979           0.0        1.0   \n",
       "1            0.9900             0.9900           0.0        0.0   \n",
       "2            0.9978             0.9975           0.0        0.0   \n",
       "3            0.9971             0.9975           0.0        1.0   \n",
       "4            0.9984             0.9977           0.0        1.0   \n",
       "\n",
       "   oe_constraint  ppap_risk  stop_auto_buy  rev_stop  \n",
       "0            1.0        1.0            0.0       1.0  \n",
       "1            1.0        0.0            0.0       1.0  \n",
       "2            1.0        1.0            0.0       1.0  \n",
       "3            1.0        1.0            0.0       1.0  \n",
       "4            1.0        1.0            0.0       1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#num_columns = ['national_inv','lead_time','in_transit_qty','forecast_3_month','forecast_6_month',\n",
    "#              'forecast_9_month','sales_1_month','sales_3_month','sales_6_month','sales_9_month','min_bank',\n",
    "#              'pieces_past_due','perf_6_month_avg','perf_12_month_avg','local_bo_qty']\n",
    "#features_scaled = X_sampled[num_columns]\n",
    "#features_scaled.info()\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_sampled)\n",
    "X_sampled = pd.DataFrame(scaler.transform(X_sampled), index=X_sampled.index, columns=X_sampled.columns)\n",
    "\n",
    "X_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_sampled,y_sampled,test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Pipeline\n",
    "\n",
    "In this section, we design an operationalized machine learning pipeline, which includes:\n",
    "\n",
    "* Anomaly detection\n",
    "* Dimensionality Reduction\n",
    "* Train a model\n",
    "\n",
    "We are free to use any of the models that we learned in the past or use new models. \n",
    "\n",
    "* It is difficult to fit an anomaly detection method in the sklearn pipeline without writing custom codes. For simplicity, we avoid fitting an anomaly detection method within a pipeline. So we can create the workflow in two steps. \n",
    "    * Step I: fit an outlier with the training set\n",
    "    * Step II: define a pipeline using a feature selection and a classification method. Then cross-validate this pipeline using the training data without outliers. \n",
    "        * Note: if your smart sample is somewhat imbalanced, you might want to change the scoring method in GridSearchCV (see the [doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)).\n",
    "\n",
    "* Once we fit the pipeline, we identify the best model and give an unbiased evaluation using the test set that we created in Part II. For unbiased evaluation we report confusion matrix, precision, recall, f1-score, accuracy, and other measures if you like. \n",
    "\n",
    "(Optional) Those who are interested in writing custom codes for adding an outlier detection method into the sklearn pipeline, please follow this discussion [thread](https://stackoverflow.com/questions/52346725/can-i-add-outlier-detection-and-removal-to-scikit-learn-pipeline). \n",
    "\n",
    "\n",
    "**Note:** <span style='background:yellow'>We will be using Grid Search to find the optimal parameters of the pipelines.</span>\n",
    "\n",
    "You can add more notebook cells or import any Python modules as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 1st pipeline \n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation\n",
    "  \n",
    "Add cells as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add anomaly detection code  (Question #E201)\n",
    "# ----------------------------------\n",
    "\n",
    "envelope = EllipticEnvelope(support_fraction=1, contamination=0.2).fit(X_train)\n",
    "outliers = envelope.predict(X_train)==-1\n",
    "X_train_clean = X_train[~outliers]\n",
    "y_train_clean = y_train[~outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E202)\n",
    "# ----------------------------------\n",
    "param_grid = {'PCA__n_components': [5,10,15,20],\n",
    "             'SVC__C': [1,5,10,15,20,25],\n",
    "             }\n",
    "\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('PCA', PCA()),\n",
    "    ('SVC', SVC(kernel='rbf'))\n",
    "])\n",
    "\n",
    "grid_model = GridSearchCV(pipe, param_grid = param_grid, n_jobs = 5, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('PCA', PCA(n_components=10)), ('SVC', SVC(C=15))])\n"
     ]
    }
   ],
   "source": [
    "grid_model.fit(X_train_clean,y_train_clean)\n",
    "print(grid_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.57      0.57      2275\n",
      "           1       0.56      0.55      0.55      2243\n",
      "\n",
      "    accuracy                           0.56      4518\n",
      "   macro avg       0.56      0.56      0.56      4518\n",
      "weighted avg       0.56      0.56      0.56      4518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E203)\n",
    "# ----------------------------------\n",
    "predicted_y = grid_model.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1302</td>\n",
       "      <td>973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  1302   973\n",
       "1  1013  1230"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test,predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E204)\n",
    "# ---------------------------------------------\n",
    "\n",
    "Optimal parameters were n_components = 10 for PCA and C=15 for the SVC.  This gave the model a 56% return accuracy overall and a 55% precision and a 55% return accuracy on backordered items.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 2nd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add anomaly detection code  (Question #E205)\n",
    "# ----------------------------------\n",
    "iso = IsolationForest(contamination=0.05).fit(X_train,y_train)\n",
    "iso_outliers = iso.predict(X_train)==-1\n",
    "X_train_clean2 = X_train[~iso_outliers]\n",
    "y_train_clean2 = y_train[~iso_outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E206)\n",
    "# ----------------------------------\n",
    "\n",
    "param_grid2 = {'sKb__k': [5,10,15,20],\n",
    "              'DT__max_depth': [2,3,4,5,6,7,8,9,10,15,20]}\n",
    "pipe2 = Pipeline([\n",
    "    ('sKb',SelectKBest(score_func=chi2)),\n",
    "    ('DT',DecisionTreeClassifier(criterion='gini'))\n",
    "])\n",
    "\n",
    "grid_model2 = GridSearchCV(pipe2, param_grid = param_grid2, n_jobs = 5, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('sKb',\n",
      "                 SelectKBest(k=20,\n",
      "                             score_func=<function chi2 at 0x7efe70257840>)),\n",
      "                ('DT', DecisionTreeClassifier(max_depth=9))])\n"
     ]
    }
   ],
   "source": [
    "grid_model2.fit(X_train_clean2,y_train_clean2)\n",
    "print(grid_model2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87      2275\n",
      "           1       0.87      0.85      0.86      2243\n",
      "\n",
      "    accuracy                           0.86      4518\n",
      "   macro avg       0.86      0.86      0.86      4518\n",
      "weighted avg       0.86      0.86      0.86      4518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E207)\n",
    "# ----------------------------------\n",
    "predicted_y2 = grid_model2.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>346</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  1999   276\n",
       "1   346  1897"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test,predicted_y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E208)\n",
    "# ---------------------------------------------\n",
    "\n",
    "\n",
    "SelectKbest parameters: K= 20\n",
    "Decision Tree parameter: max depth = 9\n",
    "                         criterion = gini\n",
    "Returned an accuracy of 86% overall and a precision on backordered items of 87% and a recall of 85% on the same.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 3rd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add anomaly detection code  (Question #E209)\n",
    "# ----------------------------------\n",
    "lof = LocalOutlierFactor(novelty=False).fit(X_train,y_train)\n",
    "lof_outliers = lof.fit_predict(X_train)==-1\n",
    "X_train_clean3 = X_train[~lof_outliers]\n",
    "y_train_clean3 = y_train[~lof_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E210)\n",
    "# ----------------------------------\n",
    "param_grid3 = {'RF__n_estimators': [1,2,3,4,5,6,7,8,9,10],\n",
    "               'RF__max_depth': [10,20,30,40,50,60,70,80,100]\n",
    "              }\n",
    "pipe3 = Pipeline([\n",
    "    ('VT',VarianceThreshold()),\n",
    "    ('RF',RandomForestClassifier(criterion='entropy'))\n",
    "])\n",
    "\n",
    "grid_model3 = GridSearchCV(pipe3, param_grid = param_grid3, n_jobs = 5, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('VT', VarianceThreshold()),\n",
      "                ('RF',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=70,\n",
      "                                        n_estimators=9))])\n"
     ]
    }
   ],
   "source": [
    "grid_model3.fit(X_train_clean3,y_train_clean3)\n",
    "print(grid_model3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      2275\n",
      "           1       0.91      0.88      0.89      2243\n",
      "\n",
      "    accuracy                           0.89      4518\n",
      "   macro avg       0.89      0.89      0.89      4518\n",
      "weighted avg       0.89      0.89      0.89      4518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E211)\n",
    "# ----------------------------------\n",
    "predicted_y3 = grid_model3.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2075</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280</td>\n",
       "      <td>1963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2075   200\n",
       "1   280  1963"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test,predicted_y3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E212)\n",
    "# ---------------------------------------------\n",
    "Random Forest parameters:   Max Depth = 70\n",
    "                            N estimators = 9\n",
    "                            Criterion = entropy\n",
    "\n",
    "Returned an accuracy of 89% overall and a precision on backordered items of 91% and a recall of 88% on the same.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare these three pipelines and discuss your findings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your analysis in this cell (Question #E213)\n",
    "# ----------------------------------\n",
    "\n",
    "My three pipelines were \n",
    "1) Elliptic Envelope for anamoly detection, PCA for feature reduction, and SVC for classification,\n",
    "2) Isolation Forest for anamoly detection, SelectKBest for feature reduction, and Decision Tree for classification, and\n",
    "3) Local Outlier Factor for anamoly detection, Variance Threshold for feature reduction and Random Forest for classification.\n",
    "\n",
    "The results were: \n",
    "Accuracy in classification                 1: 56% 2: 86% 3: 89%**\n",
    "Precision identifying of Backordered Items 1: 56% 2: 87% 3: 91%**\n",
    "Recall identification of backordered items 1: 55% 2: 85% 3: 88%**\n",
    "\n",
    "In all three categories pipeline model #3 outperformed the other two.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the required pipeline/models for Part III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-v1.pkl']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump([X_sampled,y_sampled,pipe3,grid_model3], 'model-v1.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have made a few commits so far of this project.  \n",
    "**Definitely make a commit of the notebook now!**  \n",
    "Comment should be: `Final Project, Checkpoint - Pipelines done`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!\n",
    "## Then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
